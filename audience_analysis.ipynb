{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "046e2757-0130-4d4d-9466-1ca4e32da50d",
   "metadata": {},
   "source": [
    "# Estimating the Audience of a Website Using Artificial Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d81b885-4fd3-4f83-b90c-2c0d7eb8b628",
   "metadata": {},
   "source": [
    "### By Mauricio Toro, PhD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54285384-824d-4895-92f4-4120e53481eb",
   "metadata": {},
   "source": [
    "### https://www.linkedin.com/in/mauricio-toro-phd/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf44e9a-35eb-4444-9830-c62bd0d04c3d",
   "metadata": {},
   "source": [
    "### http://www.github.com/mauriciotoro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57de901-88f7-4248-a831-43185d14f882",
   "metadata": {},
   "source": [
    "## Install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18561d03-0c1a-469b-a44d-bf435d3795be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --quiet boilerpy3 tabulate nltk transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60522eef-cb94-4c52-ba90-9bd5cbc6a457",
   "metadata": {},
   "source": [
    "## Import the libraries and define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6704c2e4-bb85-47c4-ab99-7ac17096325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from boilerpy3 import extractors\n",
    "import requests\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74a021d7-9b70-43e9-9a54-58fe06809e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mauriciotoro/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/mauriciotoro/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91a43574-e12a-4a1a-8869-4cb0e86157dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Extract text from URL\n",
    "\n",
    "def extract_text_from_url(url):\n",
    "    # Send a request to the website\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Check that the request was successful\n",
    "    \n",
    "    # Extract main content using boilerpy3\n",
    "    extractor = extractors.ArticleExtractor()\n",
    "    content = extractor.get_content(response.text)\n",
    "    \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3327dd8-2864-4c59-813c-7187b938d092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Text Summarization\n",
    "\n",
    "# Load pre-trained BART model and tokenizer\n",
    "model_name = 'facebook/bart-large-cnn'\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "def summarize_text(text, max_length):\n",
    "    inputs = tokenizer.batch_encode_plus([text], max_length=max_length, truncation=True, return_tensors='pt')\n",
    "    summary_ids = model.generate(inputs['input_ids'], num_beams=4, min_length=30, max_length=max_length, early_stopping=True)\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Function to summarize long texts\n",
    "def summarize_long_text(long_text, max_length = 130, chunk_size=512, long = False):\n",
    "    text_chunks = [long_text[i:i+chunk_size] for i in range(0, len(long_text), chunk_size)]\n",
    "    summaries = [summarize_text(chunk,max_length) for chunk in text_chunks]\n",
    "    if long:\n",
    "        return '. '.join(summaries)\n",
    "    else:    \n",
    "        return summarize_text('. '.join(summaries),max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2000a1ff-fffb-4251-8cd6-76879e4c4c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Emotion Analysis\n",
    "\n",
    "# Load the pre-trained emotion detection model and pipeline\n",
    "emotion_pipeline = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\")\n",
    "\n",
    "def detect_emotion(text, chunk_size=512):\n",
    "    # Split the text into chunks\n",
    "    text_chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "    \n",
    "    # Detect emotion for each chunk\n",
    "    emotions = []\n",
    "    for chunk in text_chunks:\n",
    "        result = emotion_pipeline(chunk)\n",
    "        # Get the emotion label with the highest score for each chunk\n",
    "        emotion_label = max(result, key=lambda x: x['score'])['label']\n",
    "        emotions.append(emotion_label)\n",
    "    \n",
    "    return emotions\n",
    "\n",
    "def get_most_common_emotion(emotions):\n",
    "    # Count the occurrences of each emotion\n",
    "    emotion_counts = Counter(emotions)\n",
    "    # Get the most common emotion\n",
    "    most_common_emotion = emotion_counts.most_common(1)[0][0]\n",
    "    return most_common_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6735ef8-e4a2-4e74-82cd-cb34d788d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Zero Shot Classification\n",
    "def get_top_zero_shot_prediction(text,category_list):\n",
    "    zero_shot_pipeline = pipeline(model=\"facebook/bart-large-mnli\")\n",
    "    results = zero_shot_pipeline(plain_text,category_list, multi_label=False)\n",
    "    return results['labels'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94f11611-fcd5-4474-a2b5-f2313a7a448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Get keywords excluding verbs\n",
    "def get_keywords_from_text(text):\n",
    "    # Tokenize and POS tagging\n",
    "    tokens = word_tokenize(text)\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    \n",
    "    # Filter out verbs\n",
    "    non_verbs = [word for word, pos in pos_tags if pos not in ('VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ')]\n",
    "    \n",
    "    # Join non-verbs into a cleaned text\n",
    "    cleaned_text = ' '.join(non_verbs)\n",
    "    \n",
    "    # Vectorize and extract keywords\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    X = vectorizer.fit_transform([cleaned_text])\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Return the words with the highest TF-IDF scores for the document\n",
    "    scores = X[0].T.todense().A1\n",
    "    sorted_items = sorted(zip(scores, feature_names), reverse=True)\n",
    "    return [word for score, word in sorted_items[:5]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acd40dd3-0ae9-4973-9445-872e0dace85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Get the audience analysis\n",
    "\n",
    "# Define the types of audience we want to analyse\n",
    "audience_types = [\"gender\", \"age\", \"income\", \"location\"]\n",
    "\n",
    "def get_audience_analysis(text):\n",
    "    # Define the possible values for each type of audience\n",
    "    audience_category_lists = [ [\"resonates with men\",\"resonates with women\"],\\\n",
    "                          [\"resonates with young people\",\"resonates with middle age people\", \"resonates with old people\"],\\\n",
    "                          [\"resonates with low income\",\"resonates with medium income\", \"resonates with high income\"],\\\n",
    "                          [\"resonates with urban people\", \"resonates with rural people\"],\\\n",
    "                        ]    \n",
    "    audience_dict = {}\n",
    "    for index, category_list in enumerate(audience_category_lists):\n",
    "        # Use a zero shot classifier to obtain the audience for each category\n",
    "        audience_dict[audience_types[index]] = get_top_zero_shot_prediction(plain_text, category_list)\n",
    "    return audience_dict "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be4deaf-399a-4a83-9078-4698b35e4676",
   "metadata": {},
   "source": [
    "## Define the URLs of the websites to extract the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64616545-4fcf-4b1c-9a94-1fd0e993d6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://medium.com/@mauriciotorob/streamlining-transaction-categorisation-at-scale-part-2-6f00e8180418\",\n",
    "    \"https://www.theguardian.com/technology/article/2024/jul/22/crowdstrike-says-significant-number-of-devices-back-online-after-global-outage\",\n",
    "    \"https://www.estherperel.com/focus-on-categories/infidelity\",\n",
    "    \"https://www.bbc.co.uk/news/articles/cn078lznklxo\",\n",
    "    \"https://www.safecosmetics.org/resources/safe-cosmetics-tips/\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffd5928-722e-4d68-8648-0e5e836ccd14",
   "metadata": {},
   "source": [
    "## Generate summary, emotions, keywords and audience analysis for all the websites in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51560784-5326-4e8a-8a44-bdfed7823707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Process each URL\n",
    "for url in urls:\n",
    "    # Extract and process data\n",
    "    plain_text = extract_text_from_url(url)\n",
    "    summary = summarize_long_text(plain_text)\n",
    "    emotions = detect_emotion(plain_text)\n",
    "    most_common_emotion = get_most_common_emotion(emotions)\n",
    "    keywords = get_keywords_from_text(plain_text)\n",
    "    audience_dict = get_audience_analysis(plain_text)\n",
    "    \n",
    "    # Create a row of data\n",
    "    row = {\n",
    "        'url': url,\n",
    "        'summary': summary,\n",
    "        'emotions': \", \".join(emotions),\n",
    "        'keywords': \", \".join(keywords),\n",
    "        'most_common_emotion': most_common_emotion\n",
    "    }\n",
    "    \n",
    "    # Add audience predictions to the row\n",
    "    for audience_type in audience_types:\n",
    "        row[audience_type] = audience_dict.get(audience_type, '')\n",
    "    \n",
    "    # Append the row to the data list\n",
    "    data.append(row)\n",
    "\n",
    "# Create a dataframe from the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the dataframe to a CSV file (optional)\n",
    "df.to_csv('output.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979cb835-84d5-45bc-8a92-c2cbff0b8bce",
   "metadata": {},
   "source": [
    "## Display a table with the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80539fb7-8b45-4b71-9b63-231fc62d9c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>url                                                                                                                                      </th><th>summary                                                                                                                                                                                                                                                                                                                                                     </th><th>emotions                                                                                                           </th><th>keywords                                           </th><th>most_common_emotion  </th><th>gender              </th><th>age                             </th><th>income                      </th><th>location                   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>https://medium.com/@mauriciotorob/streamlining-transaction-categorisation-at-scale-part-2-6f00e8180418                                   </td><td>In the first part of our blog, we talked about the user-centric approach Cheddar adopted to enhance its Personal Finance Manager (PFM) This involved mapping transaction types to spending categories, ensuring the system was intuitive and useful for users. As we move into the second part, we will explore the processes of data cleaning and mappings.</td><td>neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral, neutral</td><td>merchant, data, banks, transaction, scientists     </td><td>neutral              </td><td>resonates with men  </td><td>resonates with old people       </td><td>resonates with medium income</td><td>resonates with urban people</td></tr>\n",
       "<tr><td>https://www.theguardian.com/technology/article/2024/jul/22/crowdstrike-says-significant-number-of-devices-back-online-after-global-outage</td><td>CrowdStrike says significant number of devices back online after global outage. But experts says full recovery from Friday&#x27;s IT failure could take weeks. Thousands of flights were cancelled, broadcasters were forced off air and millions of PCs failed to start after a CrowdStrike software update.                                                    </td><td>neutral, sadness, neutral, sadness, sadness, sadness, sadness                                                      </td><td>crowdstrike, number, friday, devices, company      </td><td>sadness              </td><td>resonates with women</td><td>resonates with young people     </td><td>resonates with medium income</td><td>resonates with urban people</td></tr>\n",
       "<tr><td>https://www.estherperel.com/focus-on-categories/infidelity                                                                               </td><td>Infidelity is often the first time couples broach conversations they&#x27;ve avoided for years. I prefer to use infidelity as a portal into the complex nature of love. Get clarity on your most intimate romantic relationships.                                                                                                                                </td><td>neutral, surprise                                                                                                  </td><td>relationships, infidelity, conversations, sex, life</td><td>neutral              </td><td>resonates with women</td><td>resonates with young people     </td><td>resonates with medium income</td><td>resonates with rural people</td></tr>\n",
       "<tr><td>https://www.bbc.co.uk/news/articles/cn078lznklxo                                                                                         </td><td>Village has &#x27;desperate need&#x27; for new medical centre near Norwich. Almost 4,000 more homes have been proposed for Rackheath. Construction work will begin on 5 August and should be complete in spring.                                                                                                                                                      </td><td>fear, joy, joy, neutral                                                                                            </td><td>centre, medical, village, rackheath, 000           </td><td>joy                  </td><td>resonates with men  </td><td>resonates with middle age people</td><td>resonates with medium income</td><td>resonates with rural people</td></tr>\n",
       "<tr><td>https://www.safecosmetics.org/resources/safe-cosmetics-tips/                                                                             </td><td>Choose products with simpler ingredient lists and hidden ‘fragrance’ ingredients. Avoid products with ‘parfum’ on the label which can hide any number of chemicals. Use Tools like Clearya and Think Dirty to find out whether your go-to products are safe.                                                                                                </td><td>neutral, neutral, neutral, neutral, neutral                                                                        </td><td>products, ingredients, safe, toxic, care           </td><td>neutral              </td><td>resonates with women</td><td>resonates with young people     </td><td>resonates with medium income</td><td>resonates with urban people</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the dataframe as a table\n",
    "table_html = tabulate(df, headers='keys', tablefmt='html', showindex=False)\n",
    "\n",
    "# Use IPython.display to render the table\n",
    "display(HTML(table_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f293f7-1fcd-4bd9-8674-064c372e71ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a361d276-4b3c-4532-95da-140ff4c87259",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
